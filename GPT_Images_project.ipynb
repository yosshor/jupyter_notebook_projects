{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNL8onHMNg54/y6kzsYFbVH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yosshor/jupyter_notebook_projects/blob/master/GPT_Images_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "L6cz6JqBvTa6",
        "outputId": "0935f37a-48f3-4dfc-a472-79863f579d7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |███████▎                        | 10 kB 20.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 20 kB 22.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 30 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 40 kB 4.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 44 kB 1.8 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 147 kB 9.3 MB/s \n",
            "\u001b[?25h  Building wheel for openai (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 13.8 MB 5.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 278 kB 79.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 2.3 MB 62.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 106 kB 50.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 84 kB 3.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 84 kB 2.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 64 kB 2.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 80 kB 9.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 69 kB 7.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 58 kB 5.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.5 MB/s \n",
            "\u001b[?25h  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for python-multipart (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyTelegramBotAPI\n",
            "  Downloading pyTelegramBotAPI-4.8.0.tar.gz (217 kB)\n",
            "\u001b[K     |████████████████████████████████| 217 kB 4.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from pyTelegramBotAPI) (2.23.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->pyTelegramBotAPI) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->pyTelegramBotAPI) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->pyTelegramBotAPI) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->pyTelegramBotAPI) (1.24.3)\n",
            "Building wheels for collected packages: pyTelegramBotAPI\n",
            "  Building wheel for pyTelegramBotAPI (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyTelegramBotAPI: filename=pyTelegramBotAPI-4.8.0-py3-none-any.whl size=200125 sha256=ee6997f90575c9179b2c0085b32d46f754062d9523c5ad9ad01c391cfed53a59\n",
            "  Stored in directory: /root/.cache/pip/wheels/c2/05/70/8409792e663e67a70e057df1f18d070105c1c457b3f410bbb0\n",
            "Successfully built pyTelegramBotAPI\n",
            "Installing collected packages: pyTelegramBotAPI\n",
            "Successfully installed pyTelegramBotAPI-4.8.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting Google-Images-Search\n",
            "  Downloading Google_Images_Search-1.4.6-py2.py3-none-any.whl (12 kB)\n",
            "Collecting termcolor~=1.1\n",
            "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
            "Collecting Pillow>=8.1.1\n",
            "  Downloading Pillow-9.3.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 4.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six~=1.12 in /usr/local/lib/python3.8/dist-packages (from Google-Images-Search) (1.15.0)\n",
            "Collecting google-api-python-client~=2.48.0\n",
            "  Downloading google_api_python_client-2.48.0-py2.py3-none-any.whl (8.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.5 MB 54.0 MB/s \n",
            "\u001b[?25hCollecting python-resize-image~=1.1\n",
            "  Downloading python_resize_image-1.1.20-py2.py3-none-any.whl (8.4 kB)\n",
            "Requirement already satisfied: requests~=2.21 in /usr/local/lib/python3.8/dist-packages (from Google-Images-Search) (2.23.0)\n",
            "Collecting pyfiglet~=0.8\n",
            "  Downloading pyfiglet-0.8.post1-py2.py3-none-any.whl (865 kB)\n",
            "\u001b[K     |████████████████████████████████| 865 kB 67.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click>=7.0<=8.1.* in /usr/local/lib/python3.8/dist-packages (from Google-Images-Search) (7.1.2)\n",
            "Collecting colorama~=0.4\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client~=2.48.0->Google-Images-Search) (3.0.1)\n",
            "Collecting google-auth-httplib2>=0.1.0\n",
            "  Downloading google_auth_httplib2-0.1.0-py2.py3-none-any.whl (9.3 kB)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client~=2.48.0->Google-Images-Search) (0.17.4)\n",
            "Requirement already satisfied: google-auth<3.0.0dev,>=1.16.0 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client~=2.48.0->Google-Images-Search) (2.15.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.8/dist-packages (from google-api-python-client~=2.48.0->Google-Images-Search) (2.8.2)\n",
            "Requirement already satisfied: protobuf<5.0.0dev,>=3.15.0 in /usr/local/lib/python3.8/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client~=2.48.0->Google-Images-Search) (3.19.6)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.8/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-api-python-client~=2.48.0->Google-Images-Search) (1.57.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3.0.0dev,>=1.16.0->google-api-python-client~=2.48.0->Google-Images-Search) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3.0.0dev,>=1.16.0->google-api-python-client~=2.48.0->Google-Images-Search) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3.0.0dev,>=1.16.0->google-api-python-client~=2.48.0->Google-Images-Search) (5.2.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=1.16.0->google-api-python-client~=2.48.0->Google-Images-Search) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests~=2.21->Google-Images-Search) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests~=2.21->Google-Images-Search) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests~=2.21->Google-Images-Search) (2022.12.7)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests~=2.21->Google-Images-Search) (3.0.4)\n",
            "Building wheels for collected packages: termcolor\n",
            "  Building wheel for termcolor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4849 sha256=9ad1d04d8f8f9a412c1ee4a1d90d99f3bae048f77e2c96c353ef44fb03da6c70\n",
            "  Stored in directory: /root/.cache/pip/wheels/a0/16/9c/5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
            "Successfully built termcolor\n",
            "Installing collected packages: Pillow, google-auth-httplib2, termcolor, python-resize-image, pyfiglet, google-api-python-client, colorama, Google-Images-Search\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 7.1.2\n",
            "    Uninstalling Pillow-7.1.2:\n",
            "      Successfully uninstalled Pillow-7.1.2\n",
            "  Attempting uninstall: google-auth-httplib2\n",
            "    Found existing installation: google-auth-httplib2 0.0.4\n",
            "    Uninstalling google-auth-httplib2-0.0.4:\n",
            "      Successfully uninstalled google-auth-httplib2-0.0.4\n",
            "  Attempting uninstall: termcolor\n",
            "    Found existing installation: termcolor 2.1.1\n",
            "    Uninstalling termcolor-2.1.1:\n",
            "      Successfully uninstalled termcolor-2.1.1\n",
            "  Attempting uninstall: google-api-python-client\n",
            "    Found existing installation: google-api-python-client 1.12.11\n",
            "    Uninstalling google-api-python-client-1.12.11:\n",
            "      Successfully uninstalled google-api-python-client-1.12.11\n",
            "Successfully installed Google-Images-Search-1.4.6 Pillow-9.3.0 colorama-0.4.6 google-api-python-client-2.48.0 google-auth-httplib2-0.1.0 pyfiglet-0.8.post1 python-resize-image-1.1.20 termcolor-1.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting SpeechRecognition\n",
            "  Downloading SpeechRecognition-3.9.0-py2.py3-none-any.whl (32.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 32.8 MB 249 kB/s \n",
            "\u001b[?25hCollecting requests>=2.26.0\n",
            "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26.0->SpeechRecognition) (1.24.3)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.26.0->SpeechRecognition) (2022.12.7)\n",
            "Installing collected packages: requests, SpeechRecognition\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "Successfully installed SpeechRecognition-3.9.0 requests-2.28.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gTTS\n",
            "  Downloading gTTS-2.3.0-py3-none-any.whl (26 kB)\n",
            "Collecting six~=1.16.0\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting click~=8.1.3\n",
            "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
            "\u001b[K     |████████████████████████████████| 96 kB 3.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests~=2.28.0 in /usr/local/lib/python3.8/dist-packages (from gTTS) (2.28.1)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.8/dist-packages (from requests~=2.28.0->gTTS) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests~=2.28.0->gTTS) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests~=2.28.0->gTTS) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests~=2.28.0->gTTS) (2022.12.7)\n",
            "Installing collected packages: six, click, gTTS\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.15.0\n",
            "    Uninstalling six-1.15.0:\n",
            "      Successfully uninstalled six-1.15.0\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 7.1.2\n",
            "    Uninstalling click-7.1.2:\n",
            "      Successfully uninstalled click-7.1.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.9.0 requires jedi>=0.10, which is not installed.\n",
            "flask 1.1.4 requires click<8.0,>=5.1, but you have click 8.1.3 which is incompatible.\u001b[0m\n",
            "Successfully installed click-8.1.3 gTTS-2.3.0 six-1.16.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "six"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.8/dist-packages (0.25.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pocketsphinx\n",
            "  Downloading pocketsphinx-5.0.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 29.1 MB 93.2 MB/s \n",
            "\u001b[?25hCollecting sounddevice\n",
            "  Downloading sounddevice-0.4.5-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.8/dist-packages (from sounddevice->pocketsphinx) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from CFFI>=1.0->sounddevice->pocketsphinx) (2.21)\n",
            "Installing collected packages: sounddevice, pocketsphinx\n",
            "Successfully installed pocketsphinx-5.0.0 sounddevice-0.4.5\n"
          ]
        }
      ],
      "source": [
        "!pip install -q openai\n",
        "!pip install -q gradio\n",
        "!pip install pyTelegramBotAPI\n",
        "!pip install Google-Images-Search\n",
        "!pip install SpeechRecognition\n",
        "!pip install gTTS\n",
        "!pip3 install pydub\n",
        "!pip install pocketsphinx\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkgDg0CSHMcv",
        "outputId": "193ef730-0c32-48d9-b9f2-f1c6e1aefd1b"
      },
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.8/dist-packages (0.25.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "# import gradio as gr\n",
        "import telebot\n",
        "from telebot import types\n",
        "import time\n",
        "import requests\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "import os\n",
        "import re\n",
        "from google_images_search import GoogleImagesSearch\n",
        "import nltk\n",
        "import random\n",
        "import pprint\n",
        "from nltk import Tree\n",
        "import speech_recognition as sr\n",
        "from gtts import gTTS, lang\n",
        "from os import path\n",
        "from pydub import AudioSegment  \n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4hhy3unvgAq",
        "outputId": "130a5d02-afbf-4d86-c917-9c3de79d99ef"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JWa4ZfWxwF3u"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "telid=[]\n",
        "with open('telegram_test_bot_token.txt','r') as f:\n",
        "     telid.append(f.read().split('\\n'))"
      ],
      "metadata": {
        "id": "9cWOBcI9wLRI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_token = telid[0][0]\n",
        "openai.api_key = telid[0][1]\n",
        "api_google_image_key = telid[0][2]\n",
        "your_project_cx = telid[0][3].split('=')[1]\n",
        "bot_url = f'https://api.telegram.org/bot{test_token}/'  \n",
        "url = bot_url + f'getUpdates'\n",
        "resp = requests.get(url)\n",
        "message = json.loads(resp.text)['result']\n",
        "chat_id = message[0]['message']['from']['id'] #= 319184502"
      ],
      "metadata": {
        "id": "RHq9MusmwMRI"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def openai_chat(prompt):\n",
        "    completions = openai.Completion.create(\n",
        "        engine=\"text-davinci-003\",\n",
        "        prompt=prompt,\n",
        "        max_tokens=1024,\n",
        "        n=1,\n",
        "        temperature=0.5,\n",
        "    )\n",
        "\n",
        "    message = completions.choices[0].text\n",
        "    return message.strip()"
      ],
      "metadata": {
        "id": "pCs19CGwxIiQ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_the_recipe_name(message):\n",
        "  sent = str(re.split(\":|\\.|\\n|\\!\", message)[0])\n",
        "  matches = []\n",
        "  for i in sent.split():\n",
        "    if i[0].isupper():\n",
        "      regex = \"^[A-Z]\\w*$\" #\"^\\s*(?:\\b[A-Z]+\\b[\\s]*)+(?:[:-])\\s*$\" #\n",
        "      matches.append(re.findall(regex, i))\n",
        "      print(i)\n",
        "  flat_list = [item for sublist in matches[1:] for item in sublist]\n",
        "\n",
        "  recipe_name = ' '.join(map(str,flat_list))\n",
        "  print(recipe_name)\n",
        "  return recipe_name\n",
        "\n",
        "def parse_the_recipe_name_new(message):\n",
        "  sent = str(re.split(\":|\\.|\\n|\\!\", message)[0])\n",
        "  print(sent_parse(sent)[0])\n",
        "  return sent_parse(sent)[0]\n"
      ],
      "metadata": {
        "id": "3ePoAAXE1dak"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "patterns = \"\"\"\n",
        "    NP: {<JJ>*<NN*>+}\n",
        "    {<JJ>*<NN*><CC>*<NN*>+}\n",
        "    \"\"\"\n",
        "\n",
        "NPChunker = nltk.RegexpParser(patterns)\n",
        "\n",
        "def prepare_text(input):\n",
        "    sentences = nltk.sent_tokenize(input)\n",
        "    sentences = [nltk.word_tokenize(sent) for sent in sentences]\n",
        "    sentences = [nltk.pos_tag(sent) for sent in sentences]\n",
        "    sentences = [NPChunker.parse(sent) for sent in sentences]\n",
        "    return sentences\n",
        "\n",
        "\n",
        "def parsed_text_to_NP(sentences):\n",
        "    nps = []\n",
        "    for sent in sentences:\n",
        "        tree = NPChunker.parse(sent)\n",
        "        for subtree in tree.subtrees():\n",
        "            if subtree.label() == 'NP':\n",
        "                t = subtree\n",
        "                t = ' '.join(word for word, tag in t.leaves())\n",
        "                nps.append(t)\n",
        "    return nps\n",
        "\n",
        "\n",
        "def sent_parse(input):\n",
        "    sentences = prepare_text(input)\n",
        "    nps = parsed_text_to_NP(sentences)\n",
        "    return nps\n",
        "\n",
        "def find_nps(text):\n",
        "    prepared = prepare_text(text)\n",
        "    parsed = parsed_text_to_NP(prepared)\n",
        "    final = sent_parse(parsed)"
      ],
      "metadata": {
        "id": "SBviwjung5za"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(sent_parse('I ate peanut butter and beef burger and a cup of coffee for breakfast.'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5meJQ8cyhZEv",
        "outputId": "11eac2bf-83ae-4e32-ad13-a1c1746c02b0"
      },
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['peanut butter', 'beef burger', 'cup', 'coffee', 'breakfast']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# root_dir = \"Recipes\"\n",
        "def make_dir(folder_name):\n",
        "  if not os.path.exists(folder_name):\n",
        "      os.mkdir(folder_name)\n",
        "      return True\n",
        "  return False\n",
        "# make_dir(root_dir)"
      ],
      "metadata": {
        "id": "JHmA9rXw2bmo"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy.random import seed\n",
        "from numpy.random import randint\n",
        "def download_images(recipe_name,path_to_download,chat_id,file_type):\n",
        "  gis = GoogleImagesSearch(api_google_image_key, your_project_cx)\n",
        "  _search_params = {\n",
        "      'q': f'{recipe_name}',\n",
        "      'num':100,\n",
        "      'imagesize':'500x500', #large\n",
        "      'fileType': f'{file_type}' } #jpg|gif|\n",
        "  # search first, then download and resize afterwards:\n",
        "  gis.search(search_params=_search_params,  width=500, height=500)\n",
        "  if file_type =='gif':\n",
        "    print(f'len of results : {len(gis.results())}')\n",
        "    seed(1)\n",
        "    values = randint(0, 100, 10)\n",
        "    for i in values:\n",
        "        gis.results()[i].url  # image direct url\n",
        "        print(gis.results()[i].url) \n",
        "        gis.results()[i].referrer_url  # image referrer url (source)   \n",
        "        print(gis.results()[i].referrer_url) \n",
        "        gis.results()[i].download(path_to_download)\n",
        "        bot.send_document(chat_id,document=gis.results()[i].url)\n",
        "  else:\n",
        "    for image in gis.results():\n",
        "        image.url  # image direct url\n",
        "        print(image.url) \n",
        "        image.referrer_url  # image referrer url (source)   \n",
        "        print(image.referrer_url) \n",
        "        image.download(path_to_download)  # download image\n",
        "        image.path  # downloaded local file path\n",
        "        print(f'image path : {image.path}')\n",
        "        bot.send_photo(chat_id, photo=open(image.path, 'rb'))\n",
        "\n",
        "  print('all the images downloaded successfully')"
      ],
      "metadata": {
        "id": "9GTCfCPB3_Ya"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_result(path,messasge_to_write):\n",
        "  with open(path, \"w\") as text_file:\n",
        "    text_file.write(messasge_to_write)\n",
        "  print('File saved')\n",
        "  return"
      ],
      "metadata": {
        "id": "xoSAWFEAC_s5"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def speech_to_text(filename):\n",
        "  # initialize the recognizer\n",
        "  r = sr.Recognizer()\n",
        "  # open the file\n",
        "  with sr.AudioFile(filename) as source:\n",
        "      # listen for the data (load audio to memory)\n",
        "      audio_data = r.record(source)\n",
        "      # recognize (convert from speech to text)\n",
        "      text = r.recognize_google(audio_data)\n",
        "      print(text)\n",
        "      return text"
      ],
      "metadata": {
        "id": "MIxYwxAIvUHp"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def speechToText(file_name):\n",
        "                                                                        \n",
        "    src = f\"{file_name}\"\n",
        "    dst = f\"{file_name}.wav\"\n",
        "    # convert wav to mp3     \n",
        "    # https://pythonbasics.org/convert-mp3-to-wav/                                                       \n",
        "    sound = AudioSegment.from_ogg(src)\n",
        "    sound.export(dst, format=\"wav\")\n",
        "    # Initialize the recognizer  \n",
        "    r = sr.Recognizer()  \n",
        "    AUDIO_FILE = f\"{file_name}.wav\"\n",
        "    with sr.AudioFile(AUDIO_FILE) as source:\n",
        "        audio2 = r.record(source)  # read the entire audio file\n",
        "        MyText = r.recognize_sphinx(audio2) \n",
        "        MyText = MyText.lower() \n",
        "        print(MyText)\n",
        "        return MyText\n",
        "    return -1"
      ],
      "metadata": {
        "id": "feQ2SZd6G-21"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def replace_for_result(some_str):\n",
        "  return some_str.replace('.', '\\.').replace('=', '\\=').replace('{', '\\{').replace('}', '\\}').replace('(', '\\(').replace(')', '\\)').replace('-', '\\-').replace('`', '').replace('*', '').replace('#', '\\#').replace('!', '\\!')\n",
        "\n",
        "root_dir = \"/content/Recipes\"\n",
        "\n",
        "bot = telebot.TeleBot(test_token)\n",
        "\n",
        "@bot.message_handler(content_types=['voice'])\n",
        "def voice_processing(message):\n",
        "    file_info = bot.get_file(message.voice.file_id)\n",
        "    downloaded_file = bot.download_file(file_info.file_path)\n",
        "    file_name = f'{random.randint(100000,999999)}.ogg'\n",
        "    with open(file_name, 'wb') as new_file:\n",
        "        new_file.write(downloaded_file)\n",
        "    bot.reply_to(message, \"File saved\")\n",
        "    print(f'/content/{file_name.split(\".\")[0]}')\n",
        "    text_from_voice = speechToText(f'/content/{file_name}') \n",
        "    # text_from_voice = speech_to_text('/content/new_file.ogg') \n",
        "    bot.reply_to(message, f'You Said : {text_from_voice}')\n",
        "\n",
        "@bot.message_handler(commands=['gif'])\n",
        "def voice_processing(message):\n",
        "   bot.reply_to(message, f'gif : {message.text.split(\"/gif\")[1:]}')\n",
        "   dir = '/content/new'\n",
        "   query = ' '.join(message.text.split('/gif')[1:]).lstrip()\n",
        "   download_images(query,dir,message.chat.id,'gif')\n",
        "\n",
        "\n",
        "@bot.message_handler(content_types=['text'])\n",
        "def print_result(message):\n",
        "   print(message.text)\n",
        "   resu = str(openai_chat(message.text))\n",
        "   print(type(resu))\n",
        "   print(resu)\n",
        "\n",
        "   recipe_name = parse_the_recipe_name(resu)\n",
        "   print(recipe_name)\n",
        "   if len(recipe_name.split()) == 1:\n",
        "      print(f'{recipe_name} is one word')\n",
        "      recipe_name += ' Salad'\n",
        "   path = os.path.join(root_dir, recipe_name)\n",
        "   recipe_dir = make_dir(os.path.join(root_dir, recipe_name))\n",
        "   print(recipe_dir)\n",
        "   print(f\"trying to save the result into {path}/{recipe_name}.txt\")\n",
        "   save_result(path+f'/{recipe_name}.txt',resu)\n",
        "   bot.send_message(message.chat.id,str(replace_for_result(resu)) ,parse_mode=\"MarkdownV2\")\n",
        "   try:\n",
        "     download_images(recipe_name,path,message.chat.id,'png')\n",
        "   except Exception as e:\n",
        "     bot.reply_to(message.chat.id, f'some error occured : {str(e)}')\n",
        "\n",
        "   #bot.send_message(message.chat.id,str(replace_for_result(resu)) ,parse_mode=\"MarkdownV2\")\n",
        "\n",
        "bot.polling()"
      ],
      "metadata": {
        "id": "tOdrmv4Cyw4R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "drYg0r50z1Hm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%rm -rf '/content/Recipes/Caprese Salad'\n",
        "%rm -rf '/content/Recipes'\n",
        "%mkdir '/content/Recipes'"
      ],
      "metadata": {
        "id": "vDMQ4VkpyrEB"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%rm -rf '/content/new'\n",
        "%mkdir '/content/new'"
      ],
      "metadata": {
        "id": "hRtJ901UTq-I"
      },
      "execution_count": 97,
      "outputs": []
    }
  ]
}